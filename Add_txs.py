"""
Synthetic Transmitter Addition Script

This script is used to add synthetic transmitters to videos stored in numbered directories. The videos 
are stored as sequences of images, and the transmitters are added according to a 2D Gaussian distribution, 
which is the common behavior of light sources like LEDs. Additionally, the positions of the transmitters are 
stored in the YoLo format with the aim of using the dataset generated by this algorithm. The user is prompted 
to select both transmitter and non-transmitter pixels, and this information is stored for later evaluation 
of the parameters associated with these pixels in order to determine which ones better distinguish both classes.

The script aims to facilitate the creation of a OCC dataset for tasks like object detection and tracking.
"""

import cv2
import numpy as np
import pandas as pd
import random
from matplotlib import pyplot as plt
import os

bit_duration = 0.13333  # Duración de un bit en segundos
frame_duration = 2  # Duración de una trama en segundos


def generate_frame_bits():
    """
    Generates a data frame with a randomized payload.

    The data frame format consists of:
    - 5 header bits set to 1
    - 1 bit set to 0 as a guardband
    - 4 payload bits
    - 1 bit set to 0 as a guardband
    - 4 payload bits

    Args:
        None

    Returns:
        np.array: A NumPy array representing a data frame with a shape of (1x15).
    """
    frame_bits = [1] * 5 + [0] + random.choices([0, 1], k=4) + [0] + random.choices([0, 1], k=4)

    return frame_bits


     

def create_mask(radius, std):
    """
    Creates a 2D Gaussian mask.

    Generates a 2D Gaussian mask using the specified radius and standard deviation.

    Args:
        radius (int): The radius of the mask, determining its size.
        std (float): The standard deviation, controlling the shape of the Gaussian distribution.

    Returns:
        np.array: A NumPy array representing the 2D Gaussian mask(radiusxradius).
    """
    x = np.linspace(-radius, radius, num=radius*2 + 1)
    y = np.linspace(-radius, radius, num=radius*2 + 1)
    X, Y = np.meshgrid(x, y)
    
    R2 = X**2.0 + Y**2.0
    
    profile = np.exp(-R2/2/std**2)

    return profile



def modulate_image(frame, center, radius, bit, energy):
   """
    Modulates a luminous region in a video frame according to the bit.

    This function modulates a bit state into a specified luminous region within a video frame.
    
    Args:
        frame (np.array): The video's frame to be modified.
        center (tuple): A tuple containing the coordinates (x, y) of the region's center.
        radius (int): The radius of the luminous region.
        bit (int): The bit state to be modulated (0 or 1).
        intensity_fix (float): A factor for adjusting intensity.

    Returns:
        None
    """
   if bit == 1:       
        centro_x, centro_y = center
        energy = np.random.uniform(energy - 3, energy + 3)
        mask=  np.array(energy*create_mask(radius, 
                                           radius/np.sqrt(2*np.log(radius))))[..., np.newaxis].repeat(3, axis=2)
        color_contributions = np.array([0.6, 0.6, 0.5]) # B G R
        result = (mask * color_contributions).astype(np.uint8)      
        frame[centro_x-radius:centro_x+radius + 1, centro_y-radius:centro_y + radius + 1, :] += result

def get_info(frame):
    """
    Obtains the necessary information to locate the transmitters: pixels, radius, and luminous intensity.
    Also gets the position of points not associated to transmitters that are desired to be stored for further study.
    
    Args:
        frame (np.array): Image to display for selecting transmitters.

    Returns:
        tx_centers (np.array): Numpy array containing pairs (x, y) associated with the transmitter locations.
        radius (np.array): Numpy array of integers indicating the luminous radius of each of the transmitters.
        energy (np.array): Numpy array containing integers associated with the luminous increment contributed by
        the transmitter to the image.
        non_tx_centers (np.array): Numpy array containing pairs (x, y) associated with the locations of the
        non-transmitters to be studied in post-processing.
    """
    tx_centers = []
    radius = []
    energy = []
    non_tx_centers = []
    
    ##########################  SELECT TX CENTERS ####################################
    print("Select transmitter points on the image by clicking. Press Enter to finish.")
    img = frame.copy()
    cv2.imshow("Image", img)

    points = []
    cv2.setMouseCallback("Image", click_event)

    while True:
        key = cv2.waitKey(1)
        if key == 13:  # Press "Enter" to finish the selection
            break

    cv2.destroyWindow("Image")
    tx_centers = np.array(points)
    
    ##########################  SELECT TX RADIUS ####################################
    for _ in tx_centers:
        x = input("Enter the radius for the next transmitter (or press Enter to finish): ")
        if not x:
            break
        radius.append(int(x))

    ##########################  SELECT TX ENERGY ####################################
    for _ in tx_centers:
        x = input("Enter the energy value for the next transmitter (or press Enter to finish): ")
        if not x:
            break
        energy.append(int(x))

    return tx_centers, radius, energy

def click_event(event, x, y, flags, param):
    """
    Handle mouse click events for selecting points.

    Args:
        event (int): The type of mouse event (e.g., cv2.EVENT_LBUTTONDOWN).
        x (int): The x-coordinate of the clicked point.
        y (int): The y-coordinate of the clicked point.
        flags (int): Additional flags for the mouse event.
        param (object): Additional parameter passed to the function.

    Returns:
        None
    """
    global points
    if event == cv2.EVENT_LBUTTONDOWN:
        points.append([x, y])  
   
def create_YoLo_file(transmitters, radius, width, height, output_file):
    """
    Get and store transmitters boxes in YoLo format.
    
    Args:
        transmitters(np.array): List of (x,y) coordinates of selected transmitters.
        radius(np.array): Wrotten radius for each transmitter.
        width(int): Width of the image.
        height(int): Height of the image.
        output_file(str): Name of the output file.

    Returns:
        None
    """
    with open(output_file, 'w') as file:
        for i in range(len(transmitters)):
            x_center = transmitters[i][0] / width  # Normalizing x-coordinate
            y_center = transmitters[i][1] / height  # Normalizing y-coordinate
            box_width = radius[i] / width  # Normalizing box width
            box_height = radius[i] / height  # Normalizing box height
            file.write(f"0 {x_center:.6f} {y_center:.6f} {box_width:.6f} {box_height:.6f}\n")

def store_pixels(transmitters, fps, output_file):
    """
    Store pixels positions of selected transmitters and non transmitters
    
    Args:
        transmitters (np.array): List of (x,y) coordinates of selected transmitters.
        non_transmitters (np.array): List of (x,y) coordinates of selected non transmitters.
        fps (float): Frames per second of the video
        output_file (str): The name of the output file to store the data.

    Returns:
        None
    """
    with open(output_file, 'w') as file:
        for coordinates in transmitters:
            file.write(f"T, {coordinates[0]}, {coordinates[1]}\n")
        file.write(f"FPS, {fps}\n")



def main():
    """
    Access each of the videos in each directory and extract its images and 
    main parameters (FPS, duration, number of images).

    Displays the first image of each video and asks for the position of 
    transmitters and non-transmitters, size of each light region.

    Generates and store random data frames for each transmitter and modifies  
    the images to represent those data frames in the specified positions and sizes.
    """
    # Loop through directories
    for i in range(1, 20):
        input_path = f'data/{i}' 
        input_video_file = os.path.join(input_path, 'video.mp4')
        
        # Open the video file
        cap = cv2.VideoCapture(input_video_file)
        
        # Get video properties
        frame_width = int(cap.get(3))
        frame_height = int(cap.get(4))
        total_video_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = cap.get(cv2.CAP_PROP_FPS)

        # Create VideoWriter object for saving the output video
        fourcc = cv2.VideoWriter_fourcc(*'XVID')
        output_path = f'data/{i}/out_video.mp4' 
        out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))

        # Calculate the number of frames per bit and frame duration
        number_bit_duration = round(bit_duration/(1/fps))
        number_frame_duration = round(frame_duration/(1/fps))

        # Initialize flag to display the message only once
        info_collected = False

        # Control parameters for progress
        frame_number = 0
        frame_number_bit_count = 0

        while frame_number < total_video_frames:
            # Extract frames from the video
            ret, frame = cap.read()
            if not ret:
                break
            
            # If it's the first frame of the video, collect information
            if not info_collected:
                tx_centers, radius, energy = get_info(frame)
                store_pixels(tx_centers, fps, f'data/{i}/info.txt')
                info_collected = True

            # If a frame has already been represented (frame number multiple of 60)
            if frame_number%number_frame_duration == 0:
                # Genera la secuencia de bits para cada región luminosa
                bit_sequences = [generate_frame_bits() for i in range(len(tx_centers))]
                frame_number_bit_count = 0
                print(bit_sequences)           
        
            # Calculate the bit to represent
            bit = int(frame_number_bit_count//number_bit_duration)

            # Represent bit in the image in different regions
            for i, center in enumerate(tx_centers):
                modulate_image(frame, center, radius[i], bit_sequences[i][bit], energy[i])
            
            # Store frame
            frame_filename = f'data/{i}/frame_{frame_number}.jpg'
            cv2.imwrite(frame_filename, frame)
            
            # Create YoLo - format txt file
            txt_filename = f'data/{i}/frame_{frame_number}.txt'
            create_YoLo_file(tx_centers, radius, frame_width, frame_height, txt_filename)

            # Write the frame to the ouput video
            out.write(frame)
            frame_number += 1
            frame_number_bit_count += 1

        # Release objects
        cap.release()
        out.release()
        

if __name__ == "__main__":
    main()
